[{"id":0,"href":"/posts/cerebro/","title":"Cerebro","section":"Posts","content":"정리# "},{"id":1,"href":"/posts/paper/","title":"Paper","section":"Posts","content":"Paper# "},{"id":2,"href":"/posts/book/","title":"Book","section":"Posts","content":"Book# "},{"id":3,"href":"/posts/paper/fischerImpossibilityDistributedConsensuswith/","title":"Impossibility of Distributed Consensus with One Faulty Process","section":"Paper","content":" Abstract 합의 문제는 일부가 신뢰할 수 없을 수 있는 비동기적 프로세스 시스템을 포함함. 본 논문에서의 문제는 신뢰할 수 있는 프로세스들의 이진 값 합의가 되겠다. 본 논문에서는 이 문제를 해결하기 위한 그 어떤 프로토콜이더라도, 단 하나의 결함 있는 프로세스가 있을 경우 종료되지 않을 수 있음을 보인다. 이에 반해 동기적인 경우(즉, Byzantine Generals)의 경우에는 해결할 수 있음이 알려져 있다.\n1. Introduction# 원격 프로세스간의 동의에 이르는 것이 분산 컴퓨팅에서의 핵심 문제이자, 분산 데이터 처리, 분산 파일 관리, 분산 어플리케이션의 장애 내성 등의 많은 알고리즘의 핵심이 된다.\n잘 알려진 문제의 형태로는 \u0026ldquo;transaction commit problem\u0026quot;이 있다. 이 문제는 특정 트랜젝션에 참여한 모든 데이터 관리 프로세스가 그 트랜젝션의 결과를 DB에 반영할지/말지를 결정하는 것이다. 예를 들자면, 어떠한 이유로 인해 일부 데이터 매니저가 필요한 트랜젝션 처리를 수행하는 것이 불가할 경우에는 트랜젝션을 취소해야한다. 어떤 결정이 이뤄지든간에 모든 참여자는 DB의 일관성을 유지하기 위해 반드시 같은 결정을 내려야 한다.\n\u0026ldquo;commit\u0026quot;문제에서 필요한 합의에 도달하는 것은 참여 프로세스와 네트워크가 완전히 신뢰할 수 있다면 간단하다. 그러나, 실제 시스템은 여러 결함(장애)를 겪을 수 있다. 따라서 이러한 결함이 있을 대에도 가급적 신뢰할 수 있는 합의 프로토콜이 필요하다. 물론, 그 어떤 프로토콜이라도 너무 빈번하거나 심각한 결함에 의해 실패할 수 있으므로, 기대되는 특정 수의 기대되는 결함을 견딜 수 있는 프로토콜이 최선이 될 것 이다.\n본 논문에서는 그 어떤 비동기 합의 프로토콜도 하나의 예상치 못한 결함을 견딜 수 없다는 놀라운 결과를 보인다. Byzantine 실해는 고려하지도 않을 것이고, 메세지 시스템은 신뢰할 수 있다고 가정할 것이다. 그럼에도, 이러한 가정에도, 부적절한 때에 단일 프로세스가 멈추는 것은 합의에 이르는 것을 불가능하게 한다. 따라서, 이 중요한 문제에는 컴퓨팅 환경에 대한 추가 가정이나, 허용 오류 종류에 대한 강력한 제한 없이는 솔루션이 없다.\n본 논문의 증명에서 중요한 것은 처리가 완전히 비동기적이라는 점이다. 즉, 프로세서의 상대적 속도, 메세지 전달 지연 시간에 대해서는 가정하지 않는다. 또한 프로세스가 동기화된 시계에 접근할 수 없다고 가정하므로, 타임아웃을 기반으로 하는 알고리즘을 사용할 수 없다. 마지막으로, 프로세스 종료를 감지하는 능력을 가정하지 않으므로 한 프로세스에서 다른 프로세스가 종료되었는지 여부를 알 수 없다.\n이러한 불가능성은 심지어 합의 문제의 매우 작은 형태에도 적용된다. 모든 프로세스가 {0, 1}의 이진 값 중 하나를 초기 상태로 갖는다고 가정한다. 결함없는 프로세스는 적절한 결정 상태에 들어서며 0 또는 1 중 하나의 값을 결정한다. 결정을 내리는 결함없는 모든 프로세스는 동일한 값을 선택해야한다. 불가능성의 증명을 위해서는 일부 프로세스가 최종적으로 결정을 내리기만 하면 된다. (물론, 실제로 관심 있는 알고리즘은 결국 모든 결합없는 프로세스가 결정을 내리도록 요구할 것이다.) 예를 들어, 항상 0을 선택하는 사소한 해결책 같은 것은 제외한다. 이는 초기 구성이 다를지라도 0,1이 모두 가능한 결정값이 되어야 한다고 규정했기 때문이다. 마지막 문장의 맥락이 등장하는 이유를 모르겠다.\n본 논문의 시스템 모델은 다른 곳에도 적용할 수 있을 만큼 꽤 강력하다. 프로세스들은 (무한한 상태가 있을 수 있는) 오토마타로 모델링되고, 메세지를 통해 통신한다. 하나의 단일 스텝에서, 프로세스는 메세지를 받고자 할 수 있고, 메세지 전달 여부(내용)에 따른 로컬 계산을 수행할 수 있다. 또는 임의의 유한한 메세지를 다른 프로세스에게 보낼 수 있다. 구체적으로는, \u0026ldquo;atomic broadcast\u0026quot;가 가정된다. 즉, 한 프로세스가 한 번의 스텝에 모든 타 프로세스에게 동일한 메세지를 보낼 수 있으며, 어떤 결함 없는 프로세스가 메세지를 받았다면, 모든 결함 없는 프로세스도 그 메세지를 받게 된다는 것을 보장한다. 모든 메세지는 목적지 프로세스가 무한히 수신을 시도하는 한 결국 전달된다. 그러나 메세지는 임의로 오래 지연될 수 있으며, 순서가 바뀌어 전달될 수도 있다.\n현재 사용 중인 비동기 커밋 프로토콜은 모두 \u0026ldquo;window of vulnerability\u0026quot;를 갖는 것으로 보인다. 이는 알고리즘 실행 중 단일 프로세스의 자연이나 접근 불가 상태가 전체 알고리즘을 무기한 대기 상태로 만들 수 있는 시간 간격을 의미한다. 본 논문의 불가능성 결과에 따르면 모든 커밋 프로토콜은 이러한 취약성을 가지며, 이는 널리 알려진 통념을 확인시켜 준다.\n2. Consensus Protocol# 합의 프로토콜 $P$ 는 $N \\le 2$ 는 $N$개의 프로세스로 구정소딘 비동기 시스템이다. 각 프로세스 $p$는 1 bit의 input register $x_p$와 출력 레지스터 $y_p$를 갖는다. 각 레지스터는 $\\{b, 0, 1\\}$의 값을 갖고, 무제한의 내장 공간을 갖는다. 입출력 레지스터와 프로그램 카운터, 내부 저장소를 internal state라 부른다. Initial State는 입력 레지스터를 제외한 나머지에는 고정된 값을 갖는다. 특히, 출력 레지스터는 b로 시작한다. 출력 레지스터가 0 또는 1인 상태를 결정 상태라 한다. $p$는 transition 함수에 따라 결정적으로 동작한다. transition함수는 결정 상태에 들어선 이후로는 출력 레지스터의 값을 변겨경할 수 없다. 즉 출력 레지스터는 \u0026ldquo;write-once\u0026quot;다. 전체 시스템 $P$는 각 프로세스와 관련된 transition 함수 및 입력 레지스터의 초기 값에 의해 구체화된다.\n프로세스들은 각자에게 메세지를 보내면서 통신한다. 메세지는 (p, m) 형태로, p는 목적지 프로세스 m은 유한 집합 $M$에 속한 메세지 값이 된다. 메세지 시스템은 미도착 메세지에 대한 message buffer라 불리는 multiset을 유지한다. ㅇ이는 두가지의 추상 연산을 지원한다.\n$send(p, m)$: (p, m)을 message buffer에 추가한다. $receive(p)$: message buffer에서 (p, m)을 제거하고 m을 반환한다. 이러한 경우를 전달됐다라고 말할 수 있다. 또는 특별한 널 마크 $\\varnothing$을 반환할 수 있다. 이 경우에는 버퍼를 변경하지 않고 둔다. 그러므로, 메세지 시스템은 비결정적으로 동작한다. 다만, receive(p)가 무한히 수행될 경우 메세지 버퍼의 모든 메시지가 결국 전달 된다는 조건을 만족해야 한다. 특히 메시지 시스템은 버퍼에 멧지가 존재하더라도 receive(p)에 대한 유한한 $\\varnothing$응답을 허용한다.\n시스템의 configuration(C)은 각 프로세스들의 내부 상태와 메세지 버퍼의 내용으로 구성된다. 초기 configuration은 모든 프로세스가 초기 상태에 있고, 메세지 버퍼가 비어잇는 것을 의미한다.\nstep은 한 config가 다른 config로 전의 되는 것을 의미하고 단일 프로세스 $p$의 원시 스텝으로 구성된다. 스텝은 두 단계로 이뤄진다. 우선 recieve(p)가 호출되어 값 m 또는 $\\varnothing$을 얻는다. 그 후, $p$는 구성 C에서의 내부 상태와 m에 따라 새로운 내부 상태로 진입하고, 타 프로세스에 유한한 메세지 집합을 보낸다. 프로세스는 결정적으로 동작하므로, 스텝은 전적으로 $e=(p,m)$쌍에 의해 결정된다. 이를 event (p가 m을 수신함)라 한다. $e(C)$는 e가 C에 적용되었다는 것을 의미한다. 특히, 이벤트 $(p, \\varnothing)$은 항상 구성 C에 적용될 수 있으므로, 프로세스가 또 다른 스텝을 수행하는 것은 항상 가능하다.\nC로부터의 schedule은 C에서 시작한 적용가능한 이벤트의 유/무한 시퀸스 $\\sigma$이다. 이ㄱ와 관련된 스텝의 시퀸스를 run이라 한다. 만약 $\\sigma$가 유한하다면, $\\sigma(C)$은 결과 구성을 나타내고 이를 C에서 reachable하다고 한다. 어떠한 초기 구성에서 reachable한 구성은 accessible하다고 한다. 이후로 언급하는 모든 configuration은 accessible하다고 가정한다.\n다음의 보조정리는 스케쥴의 교환가능성(commmutativity)를 나타낸다.\nLEMMA 1 어떤 구성 C로부터 스케쥴 $\\sigma_1, \\sigma_2$가 각각 구성 $C_1, C_2$로 이어진다고 하자. 만약 $C_1, C_2$에서 스텝을 수행하는 프로세스 집합이 겹치지 않는다면 $\\sigma_1$은 $C_2$에 적용될 수 있고, 그 반대 역시 가능하다. 둘 다 $C_3$로 도달한다.\n구성 C는 어떤 프로세스 p가 결정 상태에 있고, 출력 레지스터 $y_p = v$를 가지는 경우 결정 값 v를 갖는다고 한다. 합의 프로토콜은 다음의 두 조건을 만족하면 부분적으로 올바르다고 한다.\nreachable한 어떤 구성도 두 개 이상의 결정 값을 갖지 않는다. 각 $v \\in \\{0,1\\}$ 에 대해 결정 값 v를 갖는 접근 가능한 구성이 존재한다. 프로세스 p는 실행(run) 중 무한히 많은 스텝을 수행하면 결함이 없는(nonfaulty) 것으로 간주되며, 그렇지 않으면 결함이 있는(faulty) 것으로 간주된다. 실행은 적합(admissible)하다고 한다. 단, 최대 하나의 프로세스만 결함이 있고, 결함이 없는 프로세스에 전송된 모든 메시지가 결국 수신되는 경우에 한한다. 실행이 결정적(deciding)이라고 하는 것은 그 실행에서 어떤 프로세스가 결정 상태에 도달하는 경우를 의미한다.\n합의 프로토콜 P는 하나의 결함에도 불구하고 완전히 올바르다고(totally correct) 한다. 단, P가 부분적으로 올바르고, 모든 적합한 실행이 결정적 실행인 경우에 한한다. 우리의 주요 정리는 합의 문제에 대한 모든 부분적으로 올바른 프로토콜이 결정적이지 않은 적합한 실행을 가진다는 것을 보여준다.\n3. Main Result# Theorem 1\n어떤 합의 프로토콜도 하나의 결함에도 불구하고 완전히 올바를 수 없다.\nProof 하나의 결함에도 불구하고 완전히 올바른 합의 프로토콜 P가 있다고 가정하자. 일련의 보조정리를 증명해 모순에 도달할 것이다. 증명의 기본 아이디어는 프로토콜이 영원히 결정을 내리지 못하는 상황을 보여주는 것이다. 이를 위해 두 단계를 거친다.\n결정이 미리 정해지지 않은 초기 구성이 존재함을 보인다. 시스템이 특정 결정을 내리도록 만드는 스텝을 영원히 피하는 적합한 실행을 구성한다. C를 구성이라 하고 V를 C로 부터 도달가능한 구성의 결정값의 집합이라 하자.\nbivalent: |V| = 2 univalent: |V| = 1 0-valent: 결정값 0 1-valent: 결정값 1 P의 완전히 올바름과 항상 적합한 실행이 있다는 사실에 의해 $V=\\varnothing$\nLemma 2\nP는 bivalent한 초기 구성을 갖는다.\nProofs 일단 부정해보자. 그러면 P는 무조건 0-valent, 1-valent인 초기 구성을 모두 갖는다.\n어떠한 두 초기 구성이 adjacent(인접)하다고 하는 것은 두 초기 구성이 단일 프로세스 p의 초기값 $x_p$만 다르고 나머지는 모두 동일한 경우를 의미한다. 모든 초기 구성은 서로 인접한 초기 구성들의 체인으로 연결될 수 있다. 따라서, 0-valent 초기 구성 $C_0$과 1-valent $C_1$이 인접한 경우가 반드시 존재해야 한다. 이 두 구성이 다른 초기값을 가진 프로세스를 p라고 하자.\n$C_0$에서 시작하는 허용 가능한 결정 시행을 상상해보자. 어떠한 이유로 인해 프로세스 p가 메세지를 받거나 보내지 않는다. 이러한 실행의 스케줄을 $\\sigma$라고 하자. 이 $\\sigma$는 p를 제외한 다른 모든 프로세스의 동작만 포함한다. 여기서 이 스케줄은 $C_1$에서도 적용가능하다. 두 구성은 딱 하나의 프로세스 p의 초기값만 다르고, $\\sigma$에서는 p가 아무것도 하지 않기 때문에, 다른 프로세스들은 두 실행을 구분할 수 없다.\n$C_0$는 0-valent이므로 결정값 0에 도달한다. 이는 프로세스 p의 동작없이 오직 다른 프로세스들로만 이뤄진다. 이는 $C_1$에서도 동일하게 발생한다. 따라서, $C_1$도 결정값 0에 도달한다. 이는 $C_1$이 1-valent라는 가정에 모순된다. 따라서, P는 bivalent한 초기 구성을 갖는다.\nLemma 3\nP의 어떤 bivalent한 구성을 $C$라 하고, $C$에 적용 가능한 이벤트 $e = (p, m)$이라 하자. $C$에서 $e$를 적용하지 않고 도달 가능한 구성들의 집합을 $\\mathcal{E}$라 하자. 또한, $\\mathcal{D} = e(\\mathcal{E})$는 $\\mathcal{E}$에 속한 구성들에 대해 이벤트 e를 적용해 도달할 수 있는 구성들의 집합이다. 그러면 $\\mathcal{D}$는 bivalent한 구성을 포함한다.\n잠깐 정리) 그니까 이말은 e를 먼저 적용하냐 나중에 적용하냐 이건디..\nProofs e는 C에 적용 가능하므로, \u0026lsquo;$\\mathcal{E}$\u0026lsquo;의 정의와 메시지가 임의로 지연될 수 있다는 사실에 따라, e는 $\\mathcal{E}$에 속한 모든 E에 적용 가능하다. 이제 $\\mathcal{D}$에 bivalent 구성이 없다고 가정하자. 따라서 $\\mathcal{D}$에 속한 모든 구성 D는 univalent이다.\ni=0,1에 대해, C로부터 도달 가능한 i-valent 구성 $E_i$​가 존재함 (왜냐하면 C는 양가적이므로).\n만약 $E_i$가 $\\mathcal{E}$에 속한다면, $F_i = e(E_i)$는 $\\mathcal{D}$에 속한다. 그렇지 않은 경우, $E_i$​에 도달하는 과정에서 e가 적용되었을 것이므로, E$E_i$로부터 도달 가능한 $F_i \\in \\mathcal{D}$가 존재한다.\n어느 경우든 $F_i$는 i-valent이다. 왜냐하면 $F_i$​는 bivalent가 아니며(가정에 따라 $F_i \\in \\mathcal{D}$이고, $\\mathcal{D}$에는 bivalent 구성이 없으므로), $E_i$​와 $F_i$​ 중 하나는 다른 하나로부터 도달 가능하기 때문.\n$F_i​\\in \\mathcal{D}$ 이므로(i=0,1), $\\mathcal{D}$는 0-결정 구성과 1-결정 구성을 모두 포함한다.\n두 구성이 단일 단계로 인해 서로에게서 비롯될 경우 \u0026lsquo;이웃(neighbors)\u0026lsquo;이라고 하자. 쉬운 귀납법에 의해, $\\mathcal{E}$에 이웃하는 $C_0​,C_1$​이 존재하여 $D_i = e(C_i)$가 i-valent인 경우가 있다.(i=0,1) 일반성을 잃지 않고, $C_1 = e'(C_0)$라고 가정하자. 여기서 $e'=(p', m')$고 아래의 경우를 살펴보면\n만약 p′!=p라면, 보조정리 1에 의해 $D_1 = e'(D_0)$입니다. 이것은 불가능함. 왜냐하면 0-결정 구성의 어떤 후속 구성도 0-결정이어야 하기 때문. 만약 p′=p라면, C0​에서 시작하여 p가 어떤 단계도 밟지 않는 유한한 결정 실행을 고려해보자. 해당 스케줄을 $\\sigma$라고 하고, $A = \\sigma(C_0)$라고 하자. 보조정리 1에 의해 $\\sigma$는 Di​에 적용 가능하며, 이는 i-valent 구성 $E_i=\\sigma(D_i)$로 이어진다. (i=0,1). 또한 보조정리 1에 의해 e(A)=E0​이고 e(e′(A))=E1​이다. 따라서 A는 양가적이다. 그러나 이것은 불가능하다. 왜냐하면 A에 이르는 실행은 (가정에 의해) 결정 실행이므로, A는 결정적이어야 하기 때문. 각 경우에서 모순에 도달했으므로, $\\mathcal{D}$는 양가적 구성을 포함한다.\n어떤 bivalent 초기 구성에서 출발해 결정(deciding)으로 끝나는 실행은 반드시 어느 한 시점에서 bivalent에서 univalent로 변하는 단일 스텝을 포함한다. 그 한 스텝이 결국의 결정값을 가리킨다. 이제 우리는 그런 스텝들을 항상 회피하면서 시스템을 실행할 수 있음을 보이고자 한다. 그렇게 하면 적합한(nonfaulty 조건을 만족하는) 비결정 실행(admissible nondeciding run)을 구성할 수 있다.\n실행은 단계(stages)로 구성되며, 우선 프로세스들의 큐를 임의의 순서로 둔다. 각 구성의 메시지 버퍼는 메시지가 보내진 시간 순(가장 오래된 것이 먼저)이 되도록 정렬한다. 각 단계는 하나 이상의 프로세스 스텝으로 이루어지며, 그 단계는 프로세스 큐의 맨 앞에 있는 프로세스가 그 단계에서 (만약 그 프로세스의 메시지 큐가 비어있지 않았다면) 그 큐에 있는 가장 오래된 메시지를 수신하는 스텝을 처음으로 수행하는 시점에서 끝난다. 그 프로세스는 그런 스텝을 마치면 큐의 맨 뒤로 이동한다. 이러한 방식으로 무한히 많은 단계를 이어가면, 모든 프로세스는 무한히 많은 스텝을 수행하고 자신에게 보내진 모든 메시지를 결국 수신하게 된다. 따라서 그 결과 실행은 적합(admissible)하다.\n문제는 이 과정을 결정이 나오지 않도록 구성하는 것이다. Lemma 2에 의해 존재가 보장된 bivalent 초기 구성 C0에서 시작하여, 매 단계의 시작을 항상 bivalent 구성에서 하도록 유지한다. 임의의 bivalent 구성 C에서 큐의 맨 앞에 있는 프로세스를 p라 하자. C의 메시지 버퍼에 p로 향하는 가장 오래된 메시지가 있으면 그것을 m이라 하고, 없으면 m = ∅로 두자. e = (p, m)이라 두자. Lemma 3에 따르면, e가 마지막으로 적용되도록 하는 스케줄로부터 도달 가능한 bivalent 구성 C\u0026rsquo;가 존재한다. 그 스케줄을 그 단계의 스텝들로 정의하면, 그 단계는 C에서 시작하여 e를 마지막으로 적용하는 방식으로 끝나고, 단계의 끝은 역시 bivalent이 된다. 따라서 모든 단계가 성공적으로 구성되며, 무한히 이어진 실행은 적합하고(모든 프로세스가 무한히 스텝을 수행하고 보낸 메시지를 받음) 어떤 결정도 도달하지 않는다. 그러므로 프로토콜 P는 완전한 정(correctness)을 만족하지 못한다.\n4. Initially Dead Processes# 이 절에서는 실행 도중 어떤 프로세스도 죽지 않고(실행 중에 사망하지 않음), 전체 프로세스 중 과반수가 비결함(nonfaulty)일 경우 합의를 해결하는 프로토콜을 제시한다. 단, 어떤 프로세스가 처음부터 “사망(응답하지 않음)”인지 아닌지는 미리 알려져 있지 않다. 프로토콜은 두 단계로 동작한다.\n각 프로세스는 자기 번호를 브로드캐스트하고 L - 1개의 다른 프로세스로부터 메시지를 듣는다(수신한 프로세스 수가 L - 1이 되면 멈춘다). 여기서 L = ⌊(N+1)/2⌋(문맥상)의 값이다. 이로써 정점이 각 프로세스를 나타내는 방향 그래프 G를 구성한다. G에는 i → j 간선이 존재하면 j가 i로부터 메시지를 수신했다는 의미이므로, 각 정점의 indegree는 L - 1이 된다.\n각 프로세스는 G의 전이 폐포(transitive closure)인 G+를 구성한다. 단계 완료 시, 각 프로세스 k는 G+에서 자신으로 들어오는 모든 간선 (j, k)와 그들 j의 초기값을 알게 된다. 이를 위해 각 프로세스는 자신의 번호와 초기값, 그리고 1단계에서 자신이 들은 L - 1개의 프로세스 목록을 브로드캐스트한다. 그런 뒤 자신이 현재 알고 있는 모든 조상(ancestor)들로부터 2단계 메시지를 받을 때까지 기다린다. 처음에는 직접 들은 L - 1개만 알고 있지만, 받은 2단계 메시지를 통해 추가 조상들을 학습한다. 알고 있는 모든 조상들로부터 메시지를 받을 때까지 대기한다. 이 시점에서 각 프로세스는 자신이 알고 있는 조상들 및 그들에 대해 G에 인접한 간선들을 모두 알게 되므로, 각 조상들에 대해 G+에서 자신에게 들어오는 모든 간선을 계산할 수 있다.\n이 정보를 사용해 각 프로세스는 초기 클리크(initial clique)—즉 들어오는 간선이 없는 클리크—에 속하는 조상들이 누구인지 결정한다. 노드 k가 초기 클리크에 속하려면, k의 모든 조상 j에 대해 k가 j의 모든 조상의 조상(ancestor)이어야 한다는 성질을 이용한다. G+의 모든 노드는 적어도 L - 1개의 선행자를 가지므로 초기 클리크는 유일하며 크기는 적어도 L이다. 2단계를 완료한 모든 프로세스는 초기 클리크의 구성원을 정확히 알게 된다. 마지막으로 각 프로세스는 초기 클리크 구성원들의 초기값들에 기초하여 합의 규칙(사전에 합의된 규칙)을 적용해 결정을 내린다. 초기 클리크의 모든 멤버의 초기값을 모든 프로세스가 알기 때문에 같은 결론에 도달한다.\n이 프로토콜의 정당성은 다음 정리를 보인다.\n정리 2.\n실행 중 어떤 프로세스도 죽지 않고(사망하지 않으며), 초기 상태에서 엄격한 과반수(strict majority)의 프로세스가 살아 있으면(비결함이면), 모든 비결함 프로세스가 항상 결정을 내리는 부분적으로 올바른(partially correct) 합의 프로토콜이 존재한다.\n"},{"id":4,"href":"/posts/cerebro/Optimizers/","title":"Optimizers","section":"Cerebro","content":" asdfas# 최적화기란?# 최적화기의 역할# 메롱 약오르지\n최적화기의 어쩌구저쩌구# 어쩌구저쩌구~~\n$ asdfasdf $ asdfasdf $$ asdf $$ graph TD; A--\u0026gt;B; A--\u0026gt;C; B--\u0026gt;D; C--\u0026gt;D; Something# asdfasdfadfsa\ntodo# Asdfasdfas\nasdfasdf# asdfasdfasdf\nwindow Do Somthine\nMacOS do anotherthing\nasdfasdf# asdfasdf# asdfasdf# $$ \\exists \\to \\in \\mathbb{R}, x^2 = 1 $$$$ \\to \\infty \\lim_{x \\to \\infty} f(x) $$"},{"id":5,"href":"/posts/cerebro/Artificial-Intelligence/Neural-Network/Diffusion-Model-Application/","title":"Diffusion Model Application","section":"Cerebro","content":" $p(x)$, 즉, 데이터의 분포를 모델링하는 것보단 $p(x|y)$를 모델링하는 것이 유용한 경우가 많다. $y$ 는 텍스트라든지, 이미지라든지, 레이블이 될 수 있다.\nConditional Diffusion Model# $$ p_{\\theta}(x_{t-1}|x_{t},y) = N(x_{t-1}; \\mu_{\\theta}(x_{t}, t, y), \\sigma_{q}^2I) $$ Improvement(Score function)# $$ \\epsilon \\approx -\\sqrt{ 1-\\bar{\\alpha}_{t} }\\nabla_{x_{t}}\\log p(x_{t}) $$ 여기서 $\\nabla_{x_{t}}\\log p(x_{t})$를 score 또는 score function이라 부른다. 노이즈와 점수가 상수배 차이가 나므로, 점수 자체를 학습하는 신경망도 가능하다.\n유도# $$ \\begin{align} q(x_{t}|x_{0}) \u0026 = N(x_{t}; \\sqrt{ \\bar{\\alpha}_{t} }x_{0}, (1-\\bar{\\alpha}_{t})I) \\\\ \u0026 \\text{(by Tweedie's Formula)} \\\\ \\mathbb{E}[\\sqrt{ \\bar{\\alpha}_{t} }x_{0}|x_{t}] \u0026 = x_{t} + (1-\\bar{\\alpha}_{t})\\nabla_{x_{t}}\\log p(x_{t}) \\\\ \u0026 \\Leftrightarrow \\mathbb{E}[x_{t}-\\sqrt{ 1-\\bar{\\alpha}_{t} }\\epsilon|x_{t}] = x_{t} + (1-\\bar{\\alpha}_{t})\\nabla_{x_{t}}\\log p(x_{t}) \\\\ \u0026 \\Leftrightarrow\\mathbb{E}[x_{t}|x_{t}] - \\mathbb{E}[\\sqrt{ 1-\\bar{\\alpha}_{t} }\\epsilon|x_{t}] = x_{t} + (1-\\bar{\\alpha}_{t})\\nabla_{x_{t}}\\log p(x_{t}) \\\\ \u0026 \\Leftrightarrow x_{t}- \\mathbb{E}[\\sqrt{ 1-\\bar{\\alpha}_{t} }\\epsilon|x_{t}] = x_{t} + (1-\\bar{\\alpha}_{t})\\nabla_{x_{t}}\\log p(x_{t}) \\\\ \u0026 \\Leftrightarrow -\\sqrt{ 1-\\bar{\\alpha}_{t} }\\mathbb{E}[\\epsilon|x_{t}] = (1-\\bar{\\alpha}_{t})\\nabla_{x_{t}}\\log p(x_{t}) \\\\ \u0026 \\text{(by Monte Carlo)} \\\\ \u0026 \\epsilon \\approx -\\sqrt{ 1-\\bar{\\alpha}_{t} }\\nabla_{x_{t}}\\log p(x_{t}) \\end{align} $$ [!Twedie\u0026rsquo;s Formula]-\n$$ x \\sim N(x; \\mu, \\Sigma)\\text{ then }\\mathbb{E}[\\mu|x] = x + \\Sigma \\nabla_{x}\\log p(x) $$ Classifier Guidance# $$ \\begin{align} p(x_{t}|y) \u0026 = \\frac{p(x_{t})p(y|x_{t})}{p(y)} \\\\ \u0026 \\text{양변 로그, 미분} \\\\ \\nabla_{x_{t}}\\log p(x_{t}|y) \u0026 = \\nabla_{x_{t}}\\log p(x_{t}) + \\nabla_{x_{t}} \\log p(y|x_{t}) + \\nabla_{x_{t}}\\log p(y) \\\\ \\text{(조건부 점수)} \u0026 = \\text{(점수; diffusion)} \\\\ \u0026 + \\text{(분류기 로그 가능도의 기울기; 분류기 신경망으로 계산 가능)} \\\\ \u0026 + 0 \\\\ \\end{align} $$ $$ \\nabla_{x_{t}}\\log(x_{t}|y) \\approx s_{\\theta}(x_{t}, t) + \\gamma \\nabla_{x_{t}}\\log p_{\\phi}(y|x_{t}) $$ Classifier-Free Guidance# $$ \\begin{align} \\nabla_{x_{t}}\\log p(x_{t}|y) \u0026 = \\nabla_{x_{t}}\\log p(x_{t}) + \\gamma\\nabla_{x_{t}} \\log p(y|x_{t}) \\\\ \u0026 = \\nabla_{x_{t}}\\log p(x_{t}) + \\gamma\\{\\nabla_{x_{t}}\\log p(x_{t}|y) + \\nabla_{x_{t}}\\log p(y) - \\nabla_{x_{t}}\\log p(x_{t})\\} \\\\ \u0026 = \\nabla_{x_{t}}\\log p(x_{t}) + \\gamma\\{\\nabla_{x_{t}}\\log p(x_{t}|y) - \\nabla_{x_{t}}\\log p(x_{t})\\} \\end{align} $$ 조건 없는 점수, 조건부 점수 둘 다 하나의 모델로 해결할 수 있다.\n$$ \\nabla_{x_{t}}\\log p(x_{t}|y) \\approx s_{\\theta}(x_{t}, t, \\emptyset) + \\gamma\\{s_{\\theta}(x_{t}, t, y) - s_{\\theta}(x_{t}, t, \\emptyset)\\} $$ Stable Diffusion# "},{"id":6,"href":"/posts/cerebro/Artificial-Intelligence/Neural-Network/Diffusion-Model/","title":"Diffusion Model","section":"Cerebro","content":" VAE와 비교했을 때 다음의 차이가 있음\n관측 변수와 잠재 변수의 차원을 일치 고정된 정규 분포를 따르는 노이즈를 인코더에 추가. 알고리즘# x_T ~ N(0, 1) for t in [T, ..., 1]: epsilon ~ N(0, 1) if t = 1 then epsilon = 0 x_{t-1} = mu_{theta}(x_t, t) + sigma_q(t)*epsilon return x_0Diffusion Process# $$ q(x_{t}|x_{t-1}) = N(x_{t}; \\sqrt{ 1-\\beta_{t} }x_{t-1}, \\beta_{t}I) $$ Noise Sampling# $\\beta_{t}$ 값은 설정된 값(선형, 지수, 코사인파 등등)\n재매개변수화 트릭# $$ \\begin{align} \\epsilon \u0026\\sim N(0, 1) \\\\ x_{t} \u0026= \\sqrt{ 1-\\beta_{t} }x_{t-1} + \\sqrt{ \\beta_{t} }\\epsilon \\\\ \\end{align} $$ Reverse Diffusion Process# $p_{\\theta}(x_{t-1}|x_{t})$를 모델링한다. 이를 위해 아래와 같이 적용함\n$$ \\begin{align} \u0026 \\hat{x}_{t-1} = NeuralNetwork(x_{t}, t; \\theta) \\\\ \u0026 p_{\\theta}(x_{t-1}|x_{t}) = N(x_{t-1}; \\hat{x}_{t-1}, I) \\end{align} $$ Train Diffusion Model# $$ \\text{Loss}(x_{0}; \\theta) = \\cfrac{1}{\\sigma_{q}^2(t)}||\\mu_{\\theta}(x_{t}, t) - \\mu_{q}(x_{t}, t)||^2 $$ Train Diffusion Model Derivation| Dervation Variation# 바로 원본으로# $$ \\mu_{q}(x_{t},x_{0}) = \\cfrac{\\sqrt{ \\alpha_{t} }(1-\\bar{\\alpha}_{t-1})x_{t} + \\sqrt{ \\bar{\\alpha}_{t-1} }(1-\\alpha_{t})x_{0}}{1-\\bar{\\alpha}_{t}} $$ 따라서 $\\mu_{\\theta}$에 파라미터를 두는 대신 $x_{0}$자리에 파라미터를 두면 원본을 바로 복원할 수 있다.\n$$ \\mu_{\\theta}(x_{t},x_{0}) = \\cfrac{\\sqrt{ \\alpha_{t} }(1-\\bar{\\alpha}_{t-1})x_{t} + \\sqrt{ \\bar{\\alpha}_{t-1} }(1-\\alpha_{t})\\hat{x}_{\\theta}(x_{t}, t)}{1-\\bar{\\alpha}_{t}} $$ $$ D_{KL}(q(x_{t-1}|x_{t}, x_{0})||p_{\\theta}(x_{t-1}|x_{t})) = \\frac{1}{2} \\frac{1}{\\sigma^2_{q}(t)} \\left( \\frac{\\sqrt{ \\bar{\\alpha}_{t-1} }(1-\\alpha_{t})}{1-\\bar{\\alpha}_{t}} \\right)||x_{0}-\\hat{x}_{\\theta}(x_{t}, t)||^2 $$ 노이즈 예측 신경망# 앞서 본 재매개변수화 트릭의 수식으로부터\u0026hellip;\n$$ x_{0} = \\frac{x_{t}-\\sqrt{ 1-\\bar{\\alpha}_{t} }\\epsilon}{\\sqrt{ \\bar{\\alpha}_{t} }} $$ 이를 $\\mu_{q}(x_{t},x_{0})$에 대입하면\n$$ \\mu_{q}(x_{t},x_{0}) = \\frac{1}{\\sqrt{ \\alpha_{t} }}\\left( x_{t} - \\frac{1-\\alpha_{t}}{\\sqrt{ 1-\\bar{\\alpha}_{t} }}\\epsilon \\right) $$ 원본 예측 모델과 동일하게 $\\mu_{\\theta}(x_{t}, t)$를 조정하면\n$$ \\mu_{\\theta}(x_{t},x_{0}) = \\frac{1}{\\sqrt{ \\alpha_{t} }}\\left( x_{t} - \\frac{1-\\alpha_{t}}{\\sqrt{ 1-\\bar{\\alpha}_{t} }}\\epsilon_{\\theta}(x_{t}, t) \\right) $$ $$ D_{KL}(q(x_{t-1}|x_{t}, x_{0})||p_{\\theta}(x_{t-1}|x_{t})) = \\frac{1}{2} \\frac{1}{\\sigma^2_{q}(t)} \\left( \\frac{(1-\\alpha_{t})^2}{(1-\\bar{\\alpha}_{t})\\alpha_{t}} \\right)||\\epsilon-\\epsilon_{\\theta}(x_{t}, t)||^2 $$ 나머지는 상수니까 norm만 로스로 사용하면 된다.\nApplication# Diffusion-Model-Application\nDiffusion-Model-Application\n"},{"id":7,"href":"/posts/paper/%EB%8F%99%EA%B8%B0%EC%A0%81%EC%9D%B4%EB%9E%80/","title":"동기적이란","section":"Paper","content":"동기적이란?# "}]