<!doctype html><html lang=ko-kr dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content=" $p(x)$, 즉, 데이터의 분포를 모델링하는 것보단 $p(x|y)$를 모델링하는 것이 유용한 경우가 많다. $y$ 는 텍스트라든지, 이미지라든지, 레이블이 될 수 있다.
Conditional Diffusion Model# $$ p_{\theta}(x_{t-1}|x_{t},y) = N(x_{t-1}; \mu_{\theta}(x_{t}, t, y), \sigma_{q}^2I) $$ Improvement(Score function)# $$ \epsilon \approx -\sqrt{ 1-\bar{\alpha}_{t} }\nabla_{x_{t}}\log p(x_{t}) $$ 여기서 $\nabla_{x_{t}}\log p(x_{t})$를 score 또는 score function이라 부른다. 노이즈와 점수가 상수배 차이가 나므로, 점수 자체를 학습하는 신경망도 가능하다.
유도# $$ \begin{align} q(x_{t}|x_{0}) & = N(x_{t}; \sqrt{ \bar{\alpha}_{t} }x_{0}, (1-\bar{\alpha}_{t})I) \\ & \text{(by Tweedie's Formula)} \\ \mathbb{E}[\sqrt{ \bar{\alpha}_{t} }x_{0}|x_{t}] & = x_{t} + (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\ & \Leftrightarrow \mathbb{E}[x_{t}-\sqrt{ 1-\bar{\alpha}_{t} }\epsilon|x_{t}] = x_{t} + (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\ & \Leftrightarrow\mathbb{E}[x_{t}|x_{t}] - \mathbb{E}[\sqrt{ 1-\bar{\alpha}_{t} }\epsilon|x_{t}] = x_{t} + (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\ & \Leftrightarrow x_{t}- \mathbb{E}[\sqrt{ 1-\bar{\alpha}_{t} }\epsilon|x_{t}] = x_{t} + (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\ & \Leftrightarrow -\sqrt{ 1-\bar{\alpha}_{t} }\mathbb{E}[\epsilon|x_{t}] = (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\ & \text{(by Monte Carlo)} \\ & \epsilon \approx -\sqrt{ 1-\bar{\alpha}_{t} }\nabla_{x_{t}}\log p(x_{t}) \end{align} $$ [!Twedie’s Formula]-
"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://lyrad913.github.io/posts/cerebro/Artificial-Intelligence/Neural-Network/Diffusion-Model-Application/"><meta property="og:site_name" content="Segundo Cerebro"><meta property="og:title" content="Diffusion Model Application"><meta property="og:description" content="$p(x)$, 즉, 데이터의 분포를 모델링하는 것보단 $p(x|y)$를 모델링하는 것이 유용한 경우가 많다. $y$ 는 텍스트라든지, 이미지라든지, 레이블이 될 수 있다.
Conditional Diffusion Model# $$ p_{\theta}(x_{t-1}|x_{t},y) = N(x_{t-1}; \mu_{\theta}(x_{t}, t, y), \sigma_{q}^2I) $$ Improvement(Score function)# $$ \epsilon \approx -\sqrt{ 1-\bar{\alpha}_{t} }\nabla_{x_{t}}\log p(x_{t}) $$ 여기서 $\nabla_{x_{t}}\log p(x_{t})$를 score 또는 score function이라 부른다. 노이즈와 점수가 상수배 차이가 나므로, 점수 자체를 학습하는 신경망도 가능하다.
유도# $$ \begin{align} q(x_{t}|x_{0}) & = N(x_{t}; \sqrt{ \bar{\alpha}_{t} }x_{0}, (1-\bar{\alpha}_{t})I) \\ & \text{(by Tweedie's Formula)} \\ \mathbb{E}[\sqrt{ \bar{\alpha}_{t} }x_{0}|x_{t}] & = x_{t} + (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\ & \Leftrightarrow \mathbb{E}[x_{t}-\sqrt{ 1-\bar{\alpha}_{t} }\epsilon|x_{t}] = x_{t} + (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\ & \Leftrightarrow\mathbb{E}[x_{t}|x_{t}] - \mathbb{E}[\sqrt{ 1-\bar{\alpha}_{t} }\epsilon|x_{t}] = x_{t} + (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\ & \Leftrightarrow x_{t}- \mathbb{E}[\sqrt{ 1-\bar{\alpha}_{t} }\epsilon|x_{t}] = x_{t} + (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\ & \Leftrightarrow -\sqrt{ 1-\bar{\alpha}_{t} }\mathbb{E}[\epsilon|x_{t}] = (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\ & \text{(by Monte Carlo)} \\ & \epsilon \approx -\sqrt{ 1-\bar{\alpha}_{t} }\nabla_{x_{t}}\log p(x_{t}) \end{align} $$ [!Twedie’s Formula]-"><meta property="og:locale" content="ko_kr"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-08-12T23:00:48+00:00"><meta property="article:modified_time" content="2025-10-19T23:10:20+09:00"><meta property="article:tag" content="Generative_model"><meta property="article:tag" content="Diffusion"><meta property="article:tag" content="Guidance"><meta itemprop=name content="Diffusion Model Application"><meta itemprop=description content="$p(x)$, 즉, 데이터의 분포를 모델링하는 것보단 $p(x|y)$를 모델링하는 것이 유용한 경우가 많다. $y$ 는 텍스트라든지, 이미지라든지, 레이블이 될 수 있다.
Conditional Diffusion Model# $$ p_{\theta}(x_{t-1}|x_{t},y) = N(x_{t-1}; \mu_{\theta}(x_{t}, t, y), \sigma_{q}^2I) $$ Improvement(Score function)# $$ \epsilon \approx -\sqrt{ 1-\bar{\alpha}_{t} }\nabla_{x_{t}}\log p(x_{t}) $$ 여기서 $\nabla_{x_{t}}\log p(x_{t})$를 score 또는 score function이라 부른다. 노이즈와 점수가 상수배 차이가 나므로, 점수 자체를 학습하는 신경망도 가능하다.
유도# $$ \begin{align} q(x_{t}|x_{0}) & = N(x_{t}; \sqrt{ \bar{\alpha}_{t} }x_{0}, (1-\bar{\alpha}_{t})I) \\ & \text{(by Tweedie's Formula)} \\ \mathbb{E}[\sqrt{ \bar{\alpha}_{t} }x_{0}|x_{t}] & = x_{t} + (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\ & \Leftrightarrow \mathbb{E}[x_{t}-\sqrt{ 1-\bar{\alpha}_{t} }\epsilon|x_{t}] = x_{t} + (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\ & \Leftrightarrow\mathbb{E}[x_{t}|x_{t}] - \mathbb{E}[\sqrt{ 1-\bar{\alpha}_{t} }\epsilon|x_{t}] = x_{t} + (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\ & \Leftrightarrow x_{t}- \mathbb{E}[\sqrt{ 1-\bar{\alpha}_{t} }\epsilon|x_{t}] = x_{t} + (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\ & \Leftrightarrow -\sqrt{ 1-\bar{\alpha}_{t} }\mathbb{E}[\epsilon|x_{t}] = (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\ & \text{(by Monte Carlo)} \\ & \epsilon \approx -\sqrt{ 1-\bar{\alpha}_{t} }\nabla_{x_{t}}\log p(x_{t}) \end{align} $$ [!Twedie’s Formula]-"><meta itemprop=datePublished content="2025-08-12T23:00:48+00:00"><meta itemprop=dateModified content="2025-10-19T23:10:20+09:00"><meta itemprop=wordCount content="295"><meta itemprop=keywords content="Generative_model,Diffusion,Guidance"><title>Diffusion Model Application | Segundo Cerebro</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://lyrad913.github.io/posts/cerebro/Artificial-Intelligence/Neural-Network/Diffusion-Model-Application/><link rel=stylesheet href=/book.min.3f5e4eb3f51169f17085cc8ba6a8fb9309d3230597539404f629f950e544b00c.css integrity="sha256-P15Os/URafFwhcyLpqj7kwnTIwWXU5QE9in5UOVEsAw=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.7b573bba90f2e5a5026eb1b1c2a0b9a010d5e4627cbd68d8fc5a299e77106623.js integrity="sha256-e1c7upDy5aUCbrGxwqC5oBDV5GJ8vWjY/FopnncQZiM=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-posts"><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>Segundo Cerebro</span></a></h2><div class="book-search hidden"><input id=book-search-input type=text placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><input type=checkbox id=section-4ef3b6fe5ed7ba652d7aca2edff22939 class=toggle checked>
<label for=section-4ef3b6fe5ed7ba652d7aca2edff22939 class=flex><a href=/posts/cerebro/>Cerebro</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/posts/cerebro/Optimizers/>Optimizers</a></li><li><a href=/posts/cerebro/Artificial-Intelligence/Neural-Network/Diffusion-Model-Application/ class=active>Diffusion Model Application</a></li><li><a href=/posts/cerebro/Artificial-Intelligence/Neural-Network/Diffusion-Model/>Diffusion Model</a></li></ul></li><li><input type=checkbox id=section-a07d0672249f938643c621cedc8e01ec class=toggle>
<label for=section-a07d0672249f938643c621cedc8e01ec class=flex><a href=/posts/paper/>Paper</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/posts/paper/fischerImpossibilityDistributedConsensuswith/>Impossibility of Distributed Consensus with One Faulty Process</a></li><li><a href=/posts/paper/%EB%8F%99%EA%B8%B0%EC%A0%81%EC%9D%B4%EB%9E%80/>동기적이란</a></li></ul></li><li><input type=checkbox id=section-b097725cba862b5d546cf6eef665ce9f class=toggle>
<label for=section-b097725cba862b5d546cf6eef665ce9f class=flex><a href=/posts/book/>Book</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><a>Problem Solving</a><ul></ul></li></ul><ul><li><a href=/posts/>Blog</a></li><li><a href=/>Profile</a></li><li><a href=https://github.com/lyrad913 target=_blank rel=noopener>Github</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class="book-header hidden"><div class="flex align-center justify-between"><label for=menu-control><img src=/icons/menu.svg class=book-icon alt=Menu></label><h3>Diffusion Model Application</h3><label for=toc-control><img src=/icons/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class=hidden><nav id=TableOfContents><ul><li><ul><li><a href=#conditional-diffusion-model>Conditional Diffusion Model</a></li><li><a href=#improvementscore-function>Improvement(Score function)</a><ul><li><a href=#유도>유도</a></li><li><a href=#classifier-guidance>Classifier Guidance</a></li><li><a href=#classifier-free-guidance>Classifier-Free Guidance</a></li><li><a href=#stable-diffusion>Stable Diffusion</a></li></ul></li></ul></li></ul></nav></aside></header><article class="markdown book-post"><h1>Diffusion Model Application</h1><div class="flex align-center text-small book-post-date"><img src=/icons/calendar.svg class=book-icon alt=Calendar>
<span>2025-08-12</span></div><div class=text-small><a href=/tags/generative_model/>Generative_model</a>,
<a href=/tags/diffusion/>Diffusion</a>,
<a href=/tags/guidance/>Guidance</a></div><div class="book-post-content markdown-inner"><link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script><script defer src=/katex/auto-render.min.js onload='renderMathInElement(document.body,{delimiters:[{left:"$",right:"$",display:!1},{left:"$$",right:"$$",display:!0},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})'></script><p>$p(x)$, 즉, 데이터의 분포를 모델링하는 것보단 $p(x|y)$를 모델링하는 것이 유용한 경우가 많다. $y$ 는 텍스트라든지, 이미지라든지, 레이블이 될 수 있다.</p><h2 id=conditional-diffusion-model>Conditional Diffusion Model<a class=anchor href=#conditional-diffusion-model>#</a></h2><div>$$
p_{\theta}(x_{t-1}|x_{t},y) = N(x_{t-1}; \mu_{\theta}(x_{t}, t, y), \sigma_{q}^2I)
$$</div><h2 id=improvementscore-function>Improvement(Score function)<a class=anchor href=#improvementscore-function>#</a></h2><div>$$
\epsilon \approx -\sqrt{ 1-\bar{\alpha}_{t} }\nabla_{x_{t}}\log p(x_{t})
$$</div><p>여기서 $\nabla_{x_{t}}\log p(x_{t})$를 score 또는 score function이라 부른다. 노이즈와 점수가 상수배 차이가 나므로, 점수 자체를 학습하는 신경망도 가능하다.</p><h3 id=유도>유도<a class=anchor href=#%ec%9c%a0%eb%8f%84>#</a></h3><div>$$
\begin{align}
q(x_{t}|x_{0}) & = N(x_{t}; \sqrt{ \bar{\alpha}_{t} }x_{0}, (1-\bar{\alpha}_{t})I) \\
& \text{(by Tweedie's Formula)} \\
\mathbb{E}[\sqrt{ \bar{\alpha}_{t} }x_{0}|x_{t}] & = x_{t} + (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\
& \Leftrightarrow \mathbb{E}[x_{t}-\sqrt{ 1-\bar{\alpha}_{t} }\epsilon|x_{t}] = x_{t} + (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\
& \Leftrightarrow\mathbb{E}[x_{t}|x_{t}] - \mathbb{E}[\sqrt{ 1-\bar{\alpha}_{t} }\epsilon|x_{t}] = x_{t} + (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\
& \Leftrightarrow x_{t}- \mathbb{E}[\sqrt{ 1-\bar{\alpha}_{t} }\epsilon|x_{t}] = x_{t} + (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\
& \Leftrightarrow -\sqrt{ 1-\bar{\alpha}_{t} }\mathbb{E}[\epsilon|x_{t}] = (1-\bar{\alpha}_{t})\nabla_{x_{t}}\log p(x_{t}) \\
& \text{(by Monte Carlo)} \\
&
\epsilon \approx -\sqrt{ 1-\bar{\alpha}_{t} }\nabla_{x_{t}}\log p(x_{t})
\end{align}
$$</div><blockquote class=book-hint><p>[!Twedie&rsquo;s Formula]-</p><div>$$
x \sim N(x; \mu, \Sigma)\text{ then }\mathbb{E}[\mu|x] = x + \Sigma \nabla_{x}\log p(x)
$$</div></blockquote><h3 id=classifier-guidance>Classifier Guidance<a class=anchor href=#classifier-guidance>#</a></h3><p><img src=/images/cerebro/Artificial%20Intelligence/Neural%20Network/attachments/Pasted%20image%2020250813081721.png alt="attachments/Pasted image 20250813081721.png"></p><div>$$
\begin{align}
p(x_{t}|y) & = \frac{p(x_{t})p(y|x_{t})}{p(y)} \\
& \text{양변 로그, 미분} \\
\nabla_{x_{t}}\log p(x_{t}|y) & = \nabla_{x_{t}}\log p(x_{t}) + \nabla_{x_{t}} \log p(y|x_{t}) + \nabla_{x_{t}}\log p(y) \\
\text{(조건부 점수)} & = \text{(점수; diffusion)} \\
& + \text{(분류기 로그 가능도의 기울기; 분류기 신경망으로 계산 가능)} \\
& + 0 \\
\end{align}
$$</div><div>$$
\nabla_{x_{t}}\log(x_{t}|y) \approx s_{\theta}(x_{t}, t) + \gamma \nabla_{x_{t}}\log p_{\phi}(y|x_{t})
$$</div><h3 id=classifier-free-guidance>Classifier-Free Guidance<a class=anchor href=#classifier-free-guidance>#</a></h3><p><img src=/images/cerebro/Artificial%20Intelligence/Neural%20Network/attachments/Pasted%20image%2020250813083227.png alt="attachments/Pasted image 20250813083227.png"></p><div>$$
\begin{align}
\nabla_{x_{t}}\log p(x_{t}|y) & = \nabla_{x_{t}}\log p(x_{t}) + \gamma\nabla_{x_{t}} \log p(y|x_{t}) \\
& = \nabla_{x_{t}}\log p(x_{t}) + \gamma\{\nabla_{x_{t}}\log p(x_{t}|y) + \nabla_{x_{t}}\log p(y) - \nabla_{x_{t}}\log p(x_{t})\} \\
& = \nabla_{x_{t}}\log p(x_{t}) + \gamma\{\nabla_{x_{t}}\log p(x_{t}|y) - \nabla_{x_{t}}\log p(x_{t})\}
\end{align}
$$</div><p>조건 없는 점수, 조건부 점수 둘 다 하나의 모델로 해결할 수 있다.</p><div>$$
\nabla_{x_{t}}\log p(x_{t}|y) \approx s_{\theta}(x_{t}, t, \emptyset) + \gamma\{s_{\theta}(x_{t}, t, y) - s_{\theta}(x_{t}, t, \emptyset)\}
$$</div><h3 id=stable-diffusion>Stable Diffusion<a class=anchor href=#stable-diffusion>#</a></h3><p><img src=/images/cerebro/Artificial%20Intelligence/Neural%20Network/attachments/Pasted%20image%2020250813083648.png alt="attachments/Pasted image 20250813083648.png"></p><p><img src=/images/cerebro/Artificial%20Intelligence/Neural%20Network/attachments/Pasted%20image%2020250813083655.png alt="attachments/Pasted image 20250813083655.png"></p><p><img src=/images/cerebro/Artificial%20Intelligence/Neural%20Network/attachments/Pasted%20image%2020250813083705.png alt="attachments/Pasted image 20250813083705.png"></p></div></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a href=/posts/cerebro/Optimizers/ class="flex align-center"><img src=/icons/backward.svg class=book-icon alt=Backward>
<span>Optimizers</span></a></div><div><a href=/posts/cerebro/Artificial-Intelligence/Neural-Network/Diffusion-Model/ class="flex align-center"><span>Diffusion Model</span>
<img src=/icons/forward.svg class=book-icon alt=Forward></a></div></div><div class=book-comments></div><div class="book-copyright flex justify-center"><small>Segundo Cerebro - <a href=https://creativecommons.org/licenses/by/4.0/legalcode>© CC BY 4.0</a></small></div><script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#conditional-diffusion-model>Conditional Diffusion Model</a></li><li><a href=#improvementscore-function>Improvement(Score function)</a><ul><li><a href=#유도>유도</a></li><li><a href=#classifier-guidance>Classifier Guidance</a></li><li><a href=#classifier-free-guidance>Classifier-Free Guidance</a></li><li><a href=#stable-diffusion>Stable Diffusion</a></li></ul></li></ul></li></ul></nav></div></aside></main></body></html>